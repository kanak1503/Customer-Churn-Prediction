import pandas as pd
import numpy as np
import joblib
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import LabelEncoder
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import accuracy_score, classification_report
from flask import Flask, request, jsonify

# 2. Load data
df = pd.read_csv('customer_churn.csv')  # e.g., Telco dataset

# 3. Preprocess
# Convert object TotalCharges to numeric and drop NaNs
df['TotalCharges'] = pd.to_numeric(df['TotalCharges'], errors='coerce')
df.dropna(inplace=True)

# Encode categorical columns
cat_cols = df.select_dtypes(include=['object']).columns.drop('customerID')
for col in cat_cols:
    df[col] = LabelEncoder().fit_transform(df[col])

# Create feature matrix and label
X = df.drop(['customerID', 'Churn'], axis=1)
y = df['Churn'].map({'Yes':1, 'No':0})  # adjust depending on dataset encoding

# 4. Split and oversample (optional)
X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.3, random_state=42)
# Optional: from imblearn.over_sampling import SMOTE
# X_train, y_train = SMOTE().fit_resample(X_train, y_train)

# 5. Train model
model = RandomForestClassifier(n_estimators=100, random_state=42)
model.fit(X_train, y_train)

# 6. Evaluate
y_pred = model.predict(X_test)
print("Accuracy:", accuracy_score(y_test, y_pred))
print(classification_report(y_test, y_pred))

# 7. Save model and feature list
joblib.dump(model, 'churn_model.pkl')
joblib.dump(X.columns, 'feature_columns.pkl')

# 8. Simple Flask API
app = Flask(__name__)
model = joblib.load('churn_model.pkl')
cols = joblib.load('feature_columns.pkl')

@app.route('/predict', methods=['POST'])
def predict():
    data = request.json  # JSON input with feature values
    df2 = pd.DataFrame([data])
    df2 = df2[cols].reindex(columns=cols, fill_value=0)
    prob = round(float(model.predict_proba(df2)[0][1]), 3)
    return jsonify({'churn_probability': prob})

if __name__ == '__main__':
    app.run(debug=True, port=5000)
